{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ba1b3e-a294-4b4d-b59e-846f04182d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments_utils import run_maybe_remotely\n",
    "from sbi_ebm.sbibm.sbi_ebm import run as run_unle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a111d04-915d-4f56-8b30-7ce8c5c77409",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SUNLE with DIVI\n",
    "for seed in (1, 2, 3):\n",
    "    for task in (\"slcp\", \"two_moons\", \"lotka_volterra\", \"gaussian_linear_uniform\",):\n",
    "        for ns in (\n",
    "            (100,) * 10,\n",
    "            (1000,) * 10,\n",
    "            (10000,) * 10,\n",
    "        ):\n",
    "            for no in list(range(1, 10)):\n",
    "                _ = run_maybe_remotely(\n",
    "                    run_unle,\n",
    "                    folder_name=\"icml\",\n",
    "                    experience_name=\"sunle\",\n",
    "                    use_slurm=True,\n",
    "                    slurm_kwargs={},\n",
    "                    task=task,\n",
    "                    num_samples=ns,\n",
    "                    num_observation=no,\n",
    "                    num_smc_steps=5,\n",
    "                    num_mala_steps=50,\n",
    "                    use_warm_start=True,\n",
    "                    learning_rate=0.001 if task == \"lotka_volterra\" else 0.01,\n",
    "                    max_iter=10 if task==\"gaussian_linear_uniform\" and (ns==(100,)*10 or ns==(1000,)*10) else 500,\n",
    "                    weight_decay=0.1,\n",
    "                    random_seed=seed,\n",
    "                    sampler=\"mala\",\n",
    "                    num_particles=1000,\n",
    "                    batch_size=1000,\n",
    "                    restart_every=None,\n",
    "                    num_posterior_samples=10000,\n",
    "                    use_nuts=False,\n",
    "                    init_proposal=\"prior\",\n",
    "                    noise_injection_val=0.0005,\n",
    "                    proposal=\"data\",\n",
    "                    inference_sampler=\"mala\",\n",
    "                    ebm_model_type=\"likelihood\",\n",
    "                    select_based_on_test_loss=False,\n",
    "                    inference_proposal=\"prior\",\n",
    "                    use_data_from_past_rounds=True,\n",
    "                    inference_num_warmup_steps=500,\n",
    "                    exchange_mcmc_inner_sampler_num_steps=100,\n",
    "                    evaluate_posterior=True,\n",
    "                    estimate_loss=False,\n",
    "                    estimate_log_normalizer=True\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5066a8-e5bd-4428-a062-a5acafee4830",
   "metadata": {},
   "outputs": [],
   "source": [
    "### AUNLE                \n",
    "for seed in (1, 2, 3):\n",
    "    for ns in (\n",
    "        (1000,),\n",
    "        (10000,),\n",
    "        (100000,),\n",
    "    ):\n",
    "        for no in list(range(1, 10)):\n",
    "            for task in (\"slcp\", \"two_moons\", \"lotka_volterra\", \"gaussian_linear_uniform\",):\n",
    "                _ = run_maybe_remotely(\n",
    "                    run_unle,\n",
    "                    folder_name=\"icml\",\n",
    "                    experience_name=\"aunle\",\n",
    "                    use_slurm=True,\n",
    "                    slurm_kwargs={},\n",
    "                    task=task,\n",
    "                    num_samples=ns,\n",
    "                    num_observation=no,\n",
    "                    num_smc_steps=20,\n",
    "                    num_mala_steps=3,\n",
    "                    use_warm_start=True,\n",
    "                    learning_rate=0.001 if task == \"lotka_volterra\" else 0.01,\n",
    "                    max_iter=100 if task==\"gaussian_linear_uniform\" and (ns==(1000,) or ns==(10000,)) else 2000,\n",
    "                    weight_decay=0.1,\n",
    "                    random_seed=seed,\n",
    "                    sampler=\"smc\",\n",
    "                    num_particles=1000,\n",
    "                    batch_size=1000,\n",
    "                    restart_every=None,\n",
    "                    num_posterior_samples=10000,\n",
    "                    use_nuts=False,\n",
    "                    init_proposal=\"prior\",\n",
    "                    noise_injection_val=0.0005,\n",
    "                    proposal=\"prior+noise\",\n",
    "                    inference_sampler=\"smc\",\n",
    "                    ebm_model_type=\"joint_tilted\",\n",
    "                    select_based_on_test_loss=False,\n",
    "                    inference_proposal=\"prior\",\n",
    "                    use_data_from_past_rounds=False,\n",
    "                    evaluate_posterior=True\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
